{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#### APPROACHES TAKEN\n",
    "\n",
    "#### 1) Let's Mine ! Data Mining and observing features of the training set\n",
    "\n",
    "#### 2) Data Cleaning - Storing training data of different methods of cleaning and impact of data cleaning on logistic                             regression\n",
    "\n",
    "             i) tokenisation + stemming(optional removal of stop words,punctuations, numbers )\n",
    "            ii) tokenisation + lemmatization(optional removal of stop words,punctuations, numbers )\n",
    "           iii) tokenisation + data cleaning of specific types of features : stop words , numbers , punctuation ,POS tags\n",
    "             \n",
    "#### 3) Data Modelling - TFIdf vectrorizer + Logistic regression in different conditions\n",
    "\n",
    "              i) logistic regression + tokenisation + stemming\n",
    "             ii) logistic regression + tokenisation + lemmatization\n",
    "            iii) logistic regression + tokenisation + data cleaning of specific types of features : stop words , numbers ,                  punctuation ,POS tags\n",
    "\n",
    "             iv) GridSearch with cross validation to find best parameters for logistic regression\n",
    "\n",
    "              v) Logistic regression with and without n-grams (combinations with different datasets)\n",
    "\n",
    "             vi) Joint TFID vectorizer \n",
    "\n",
    "IMPORTANT  : \n",
    "Observations / Analysis / Report Summary  at the end of the Jupyter Notebook"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------\n",
    "\n",
    "### Importing the data\n",
    "\n",
    "----------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 500)\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Enjoy the opening credits. They're the best th...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Well, the Sci-Fi channel keeps churning these ...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>It takes guts to make a movie on Gandhi in Ind...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>The Nest is really just another 'nature run am...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Waco: Rules of Engagement does a very good job...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text sentiment\n",
       "0           0  Enjoy the opening credits. They're the best th...       neg\n",
       "1           1  Well, the Sci-Fi channel keeps churning these ...       neg\n",
       "2           2  It takes guts to make a movie on Gandhi in Ind...       pos\n",
       "3           3  The Nest is really just another 'nature run am...       neg\n",
       "4           4  Waco: Rules of Engagement does a very good job...       pos"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data and take a quick look\n",
    "raw_data = pd.read_csv('coursework1_train.csv')\n",
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entry num 40000\n",
      "num of pos entries 20000\n",
      "num of neg entries 20000\n"
     ]
    }
   ],
   "source": [
    "all_text = raw_data['text'].tolist()\n",
    "all_lables = raw_data['sentiment'].tolist()\n",
    "print('entry num', len(all_text))\n",
    "print('num of pos entries', len([l for l in all_lables if l=='pos']))\n",
    "print('num of neg entries', len([l for l in all_lables if l=='neg']))\n",
    "train_text = all_text[:35000]\n",
    "train_labels = all_lables[:35000]\n",
    "test_text = all_text[35000:]\n",
    "test_labels = all_lables[35000:]\n",
    "train_text_final = all_text[:40000]\n",
    "train_labels_final = all_lables[:40000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section1 : "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "### DATA MINING\n",
    "\n",
    "#### 1)Total number of words 2) Most frequent words 3) Most frequent stop words in positive and negative 4) Most common pos tags in pos and neg\n",
    "\n",
    "\n",
    "Observations :\n",
    "\n",
    "1)Stop words are the most frequent words as expected. The decision on whether or not to remove stop words from the analysis will be made later. The most frequent words may still be very usefull for classification if used the right way . \n",
    "For example : n-grams might use stop words for better results, it might catch phrases that could determine the nature of the comment\n",
    "\n",
    "2) On careful comparison of stop words of pos and negative ( there is a table below with the difference in the stopwords frequency in pos and neg reviews) No significant results observed. This eliminates the possibility of negative reviews having words like couldn't,can't,wasn't  etc being an important determining factor for classification.\n",
    "\n",
    "3) Collection of POS tags to identify if the positive or negative samples have any pos majority that can be utilized for modelling and also to analzye the pos distribution\n",
    "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fetching stopwords\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_neg_sentence = raw_data['text'][raw_data['sentiment']== 'neg']\n",
    "# pd.DataFrame(raw_data_neg_sentence,columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_list = raw_data['text'].str.lower().str.cat(sep=' ')\n",
    "words = nltk.tokenize.word_tokenize(raw_data_list)\n",
    "word_freq_dist = nltk.FreqDist(words)\n",
    "Freq_words_count = pd.DataFrame(word_freq_dist.most_common(),columns=['Word', 'Frequency'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 5 artists>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# positive words freq list\n",
    "raw_data_pos = raw_data['text'][raw_data['sentiment']== 'pos'].str.lower().str.cat(sep='')\n",
    "pos_words = nltk.tokenize.word_tokenize(raw_data_pos)\n",
    "word_freq_dist_pos = nltk.FreqDist(pos_words)\n",
    "Freq_words_count_pos = pd.DataFrame(word_freq_dist_pos.most_common(),columns=['Word', 'Frequency'])\n",
    "plt.bar(Freq_words_count_pos['Word'][:5], Freq_words_count_pos['Frequency'][:5], color='green')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>the</td>\n",
       "      <td>259485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>,</td>\n",
       "      <td>209737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>.</td>\n",
       "      <td>186742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>a</td>\n",
       "      <td>126123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>and</td>\n",
       "      <td>117807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98625</td>\n",
       "      <td>half/rest</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98626</td>\n",
       "      <td>stupid=funny</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98627</td>\n",
       "      <td>fallin</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98628</td>\n",
       "      <td>synced</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98629</td>\n",
       "      <td>non-intelligent</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>98630 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Word  Frequency\n",
       "0                  the     259485\n",
       "1                    ,     209737\n",
       "2                    .     186742\n",
       "3                    a     126123\n",
       "4                  and     117807\n",
       "...                ...        ...\n",
       "98625        half/rest          1\n",
       "98626     stupid=funny          1\n",
       "98627           fallin          1\n",
       "98628           synced          1\n",
       "98629  non-intelligent          1\n",
       "\n",
       "[98630 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# negative words list \n",
    "raw_data_neg = raw_data['text'][raw_data['sentiment']== 'neg'].str.lower().str.cat(sep=' ')\n",
    "neg_words = nltk.tokenize.word_tokenize(raw_data_neg)\n",
    "word_freq_dist_neg = nltk.FreqDist(neg_words)\n",
    "Freq_words_count_neg = pd.DataFrame(word_freq_dist_neg.most_common(),columns=['Word', 'Frequency'])\n",
    "Freq_words_count_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>me</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>my</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>myself</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>we</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>206</td>\n",
       "      <td>`</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>207</td>\n",
       "      <td>{</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>208</td>\n",
       "      <td>|</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>209</td>\n",
       "      <td>}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>~</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>211 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Word\n",
       "0         i\n",
       "1        me\n",
       "2        my\n",
       "3    myself\n",
       "4        we\n",
       "..      ...\n",
       "206       `\n",
       "207       {\n",
       "208       |\n",
       "209       }\n",
       "210       ~\n",
       "\n",
       "[211 rows x 1 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of stop words, punctuation in pos and neg\n",
    "import string\n",
    "punctuation = list(string.punctuation)\n",
    "stop_words_punctuation_df = pd.DataFrame(stop_words + punctuation,columns = ['Word'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>the</td>\n",
       "      <td>269949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>156</td>\n",
       "      <td>,</td>\n",
       "      <td>225413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>158</td>\n",
       "      <td>.</td>\n",
       "      <td>171531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>and</td>\n",
       "      <td>140333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>a</td>\n",
       "      <td>130072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>of</td>\n",
       "      <td>120744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79</td>\n",
       "      <td>to</td>\n",
       "      <td>104265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>is</td>\n",
       "      <td>91082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>159</td>\n",
       "      <td>/</td>\n",
       "      <td>78481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>83</td>\n",
       "      <td>in</td>\n",
       "      <td>78446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>164</td>\n",
       "      <td>&gt;</td>\n",
       "      <td>78355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>162</td>\n",
       "      <td>&lt;</td>\n",
       "      <td>78310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>it</td>\n",
       "      <td>73766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>i</td>\n",
       "      <td>61740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>that</td>\n",
       "      <td>55015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>this</td>\n",
       "      <td>52885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>as</td>\n",
       "      <td>40486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68</td>\n",
       "      <td>with</td>\n",
       "      <td>36496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>was</td>\n",
       "      <td>35842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67</td>\n",
       "      <td>for</td>\n",
       "      <td>35051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>but</td>\n",
       "      <td>32310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>153</td>\n",
       "      <td>)</td>\n",
       "      <td>29499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>152</td>\n",
       "      <td>(</td>\n",
       "      <td>29034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>his</td>\n",
       "      <td>26823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>you</td>\n",
       "      <td>26367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85</td>\n",
       "      <td>on</td>\n",
       "      <td>26331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>he</td>\n",
       "      <td>25102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>are</td>\n",
       "      <td>23828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>111</td>\n",
       "      <td>not</td>\n",
       "      <td>23071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>have</td>\n",
       "      <td>20276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>be</td>\n",
       "      <td>19308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>by</td>\n",
       "      <td>18963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>146</td>\n",
       "      <td>!</td>\n",
       "      <td>18834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>who</td>\n",
       "      <td>18001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>at</td>\n",
       "      <td>17813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>all</td>\n",
       "      <td>17803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>an</td>\n",
       "      <td>17754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>from</td>\n",
       "      <td>16670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>they</td>\n",
       "      <td>15322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>her</td>\n",
       "      <td>15244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>has</td>\n",
       "      <td>14574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>115</td>\n",
       "      <td>so</td>\n",
       "      <td>14132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69</td>\n",
       "      <td>about</td>\n",
       "      <td>13031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>118</td>\n",
       "      <td>very</td>\n",
       "      <td>12910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>94</td>\n",
       "      <td>there</td>\n",
       "      <td>12456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84</td>\n",
       "      <td>out</td>\n",
       "      <td>12309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>or</td>\n",
       "      <td>12065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>what</td>\n",
       "      <td>11897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>104</td>\n",
       "      <td>more</td>\n",
       "      <td>11531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>107</td>\n",
       "      <td>some</td>\n",
       "      <td>11439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>she</td>\n",
       "      <td>11415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>if</td>\n",
       "      <td>11391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>when</td>\n",
       "      <td>11354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>do</td>\n",
       "      <td>11320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>123</td>\n",
       "      <td>just</td>\n",
       "      <td>11133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>my</td>\n",
       "      <td>10143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>their</td>\n",
       "      <td>9808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>which</td>\n",
       "      <td>9541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>121</td>\n",
       "      <td>can</td>\n",
       "      <td>9499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>81</td>\n",
       "      <td>up</td>\n",
       "      <td>9223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>we</td>\n",
       "      <td>8670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>151</td>\n",
       "      <td>'</td>\n",
       "      <td>8372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>had</td>\n",
       "      <td>8195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>122</td>\n",
       "      <td>will</td>\n",
       "      <td>8154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>me</td>\n",
       "      <td>7856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>157</td>\n",
       "      <td>-</td>\n",
       "      <td>7826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>112</td>\n",
       "      <td>only</td>\n",
       "      <td>7777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>does</td>\n",
       "      <td>7735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>were</td>\n",
       "      <td>7702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>165</td>\n",
       "      <td>?</td>\n",
       "      <td>7681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>105</td>\n",
       "      <td>most</td>\n",
       "      <td>7552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>106</td>\n",
       "      <td>other</td>\n",
       "      <td>7474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>him</td>\n",
       "      <td>7448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>:</td>\n",
       "      <td>7390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>116</td>\n",
       "      <td>than</td>\n",
       "      <td>7230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>109</td>\n",
       "      <td>no</td>\n",
       "      <td>7047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>its</td>\n",
       "      <td>7025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72</td>\n",
       "      <td>into</td>\n",
       "      <td>7001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>did</td>\n",
       "      <td>6971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>how</td>\n",
       "      <td>6545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>been</td>\n",
       "      <td>6478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>because</td>\n",
       "      <td>6352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>them</td>\n",
       "      <td>5867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>161</td>\n",
       "      <td>;</td>\n",
       "      <td>5832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76</td>\n",
       "      <td>after</td>\n",
       "      <td>5707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>117</td>\n",
       "      <td>too</td>\n",
       "      <td>5421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>91</td>\n",
       "      <td>then</td>\n",
       "      <td>5249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>being</td>\n",
       "      <td>5023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>where</td>\n",
       "      <td>4929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>any</td>\n",
       "      <td>4729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63</td>\n",
       "      <td>while</td>\n",
       "      <td>4346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>these</td>\n",
       "      <td>4147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>87</td>\n",
       "      <td>over</td>\n",
       "      <td>4111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>108</td>\n",
       "      <td>such</td>\n",
       "      <td>4021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>those</td>\n",
       "      <td>4007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>93</td>\n",
       "      <td>here</td>\n",
       "      <td>3990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>your</td>\n",
       "      <td>3954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73</td>\n",
       "      <td>through</td>\n",
       "      <td>3708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>126</td>\n",
       "      <td>now</td>\n",
       "      <td>3668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>86</td>\n",
       "      <td>off</td>\n",
       "      <td>3536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>101</td>\n",
       "      <td>both</td>\n",
       "      <td>3486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>should</td>\n",
       "      <td>3449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>before</td>\n",
       "      <td>3301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>89</td>\n",
       "      <td>again</td>\n",
       "      <td>3192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>113</td>\n",
       "      <td>own</td>\n",
       "      <td>3140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>114</td>\n",
       "      <td>same</td>\n",
       "      <td>3123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71</td>\n",
       "      <td>between</td>\n",
       "      <td>3055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>103</td>\n",
       "      <td>few</td>\n",
       "      <td>2950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97</td>\n",
       "      <td>why</td>\n",
       "      <td>2793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>&amp;</td>\n",
       "      <td>2639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>102</td>\n",
       "      <td>each</td>\n",
       "      <td>2587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82</td>\n",
       "      <td>down</td>\n",
       "      <td>2552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>our</td>\n",
       "      <td>2387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>am</td>\n",
       "      <td>2101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>92</td>\n",
       "      <td>once</td>\n",
       "      <td>1949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>having</td>\n",
       "      <td>1862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>himself</td>\n",
       "      <td>1822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74</td>\n",
       "      <td>during</td>\n",
       "      <td>1816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62</td>\n",
       "      <td>until</td>\n",
       "      <td>1539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>against</td>\n",
       "      <td>1218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>itself</td>\n",
       "      <td>1199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88</td>\n",
       "      <td>under</td>\n",
       "      <td>1015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>doing</td>\n",
       "      <td>1015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>themselves</td>\n",
       "      <td>889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>myself</td>\n",
       "      <td>756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77</td>\n",
       "      <td>above</td>\n",
       "      <td>680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>herself</td>\n",
       "      <td>677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>yourself</td>\n",
       "      <td>634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>172</td>\n",
       "      <td>`</td>\n",
       "      <td>625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>whom</td>\n",
       "      <td>603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>144</td>\n",
       "      <td>won</td>\n",
       "      <td>469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>further</td>\n",
       "      <td>446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>nor</td>\n",
       "      <td>397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>148</td>\n",
       "      <td>$</td>\n",
       "      <td>386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>149</td>\n",
       "      <td>%</td>\n",
       "      <td>320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>119</td>\n",
       "      <td>s</td>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>124</td>\n",
       "      <td>don</td>\n",
       "      <td>251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>147</td>\n",
       "      <td>#</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>127</td>\n",
       "      <td>d</td>\n",
       "      <td>146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>t</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>ourselves</td>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>154</td>\n",
       "      <td>*</td>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>o</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78</td>\n",
       "      <td>below</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>174</td>\n",
       "      <td>}</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>173</td>\n",
       "      <td>{</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>169</td>\n",
       "      <td>]</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>167</td>\n",
       "      <td>[</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>166</td>\n",
       "      <td>@</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>129</td>\n",
       "      <td>m</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>hers</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>163</td>\n",
       "      <td>=</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>139</td>\n",
       "      <td>ma</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>131</td>\n",
       "      <td>re</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>155</td>\n",
       "      <td>+</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>yours</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>~</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>theirs</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>133</td>\n",
       "      <td>y</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>ours</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>yourselves</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>132</td>\n",
       "      <td>ve</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>137</td>\n",
       "      <td>haven</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>128</td>\n",
       "      <td>ll</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>135</td>\n",
       "      <td>didn</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>136</td>\n",
       "      <td>doesn</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>143</td>\n",
       "      <td>wasn</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>168</td>\n",
       "      <td>\\</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>^</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>138</td>\n",
       "      <td>isn</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>171</td>\n",
       "      <td>_</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>141</td>\n",
       "      <td>shan</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>134</td>\n",
       "      <td>couldn't</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>145</td>\n",
       "      <td>wouldn</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>142</td>\n",
       "      <td>shouldn</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>needn</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Word  Frequency\n",
       "55          the     269949\n",
       "156           ,     225413\n",
       "158           .     171531\n",
       "56          and     140333\n",
       "53            a     130072\n",
       "64           of     120744\n",
       "79           to     104265\n",
       "38           is      91082\n",
       "159           /      78481\n",
       "83           in      78446\n",
       "164           >      78355\n",
       "162           <      78310\n",
       "21           it      73766\n",
       "0             i      61740\n",
       "34         that      55015\n",
       "33         this      52885\n",
       "61           as      40486\n",
       "68         with      36496\n",
       "40          was      35842\n",
       "67          for      35051\n",
       "57          but      32310\n",
       "153           )      29499\n",
       "152           (      29034\n",
       "15          his      26823\n",
       "8           you      26367\n",
       "85           on      26331\n",
       "13           he      25102\n",
       "39          are      23828\n",
       "111         not      23071\n",
       "45         have      20276\n",
       "42           be      19308\n",
       "66           by      18963\n",
       "146           !      18834\n",
       "31          who      18001\n",
       "65           at      17813\n",
       "99          all      17803\n",
       "54           an      17754\n",
       "80         from      16670\n",
       "24         they      15322\n",
       "18          her      15244\n",
       "46          has      14574\n",
       "115          so      14132\n",
       "69        about      13031\n",
       "118        very      12910\n",
       "94        there      12456\n",
       "84          out      12309\n",
       "59           or      12065\n",
       "29         what      11897\n",
       "104        more      11531\n",
       "107        some      11439\n",
       "17          she      11415\n",
       "58           if      11391\n",
       "95         when      11354\n",
       "49           do      11320\n",
       "123        just      11133\n",
       "2            my      10143\n",
       "26        their       9808\n",
       "30        which       9541\n",
       "121         can       9499\n",
       "81           up       9223\n",
       "4            we       8670\n",
       "151           '       8372\n",
       "47          had       8195\n",
       "122        will       8154\n",
       "1            me       7856\n",
       "157           -       7826\n",
       "112        only       7777\n",
       "50         does       7735\n",
       "41         were       7702\n",
       "165           ?       7681\n",
       "105        most       7552\n",
       "106       other       7474\n",
       "14          him       7448\n",
       "160           :       7390\n",
       "116        than       7230\n",
       "109          no       7047\n",
       "22          its       7025\n",
       "72         into       7001\n",
       "51          did       6971\n",
       "98          how       6545\n",
       "43         been       6478\n",
       "60      because       6352\n",
       "25         them       5867\n",
       "161           ;       5832\n",
       "76        after       5707\n",
       "117         too       5421\n",
       "91         then       5249\n",
       "44        being       5023\n",
       "96        where       4929\n",
       "100         any       4729\n",
       "63        while       4346\n",
       "35        these       4147\n",
       "87         over       4111\n",
       "108        such       4021\n",
       "36        those       4007\n",
       "93         here       3990\n",
       "9          your       3954\n",
       "73      through       3708\n",
       "126         now       3668\n",
       "86          off       3536\n",
       "101        both       3486\n",
       "125      should       3449\n",
       "75       before       3301\n",
       "89        again       3192\n",
       "113         own       3140\n",
       "114        same       3123\n",
       "71      between       3055\n",
       "103         few       2950\n",
       "97          why       2793\n",
       "150           &       2639\n",
       "102        each       2587\n",
       "82         down       2552\n",
       "5           our       2387\n",
       "37           am       2101\n",
       "92         once       1949\n",
       "48       having       1862\n",
       "16      himself       1822\n",
       "74       during       1816\n",
       "62        until       1539\n",
       "70      against       1218\n",
       "23       itself       1199\n",
       "88        under       1015\n",
       "52        doing       1015\n",
       "28   themselves        889\n",
       "3        myself        756\n",
       "77        above        680\n",
       "20      herself        677\n",
       "11     yourself        634\n",
       "172           `        625\n",
       "32         whom        603\n",
       "144         won        469\n",
       "90      further        446\n",
       "110         nor        397\n",
       "148           $        386\n",
       "149           %        320\n",
       "119           s        253\n",
       "124         don        251\n",
       "147           #        180\n",
       "127           d        146\n",
       "120           t        145\n",
       "7     ourselves        131\n",
       "154           *        131\n",
       "130           o        128\n",
       "78        below        120\n",
       "174           }        107\n",
       "173           {        106\n",
       "169           ]         91\n",
       "167           [         85\n",
       "166           @         69\n",
       "129           m         68\n",
       "19         hers         58\n",
       "163           =         58\n",
       "139          ma         44\n",
       "131          re         43\n",
       "155           +         42\n",
       "10        yours         37\n",
       "175           ~         29\n",
       "27       theirs         29\n",
       "133           y         27\n",
       "6          ours         24\n",
       "12   yourselves         22\n",
       "132          ve         13\n",
       "137       haven         12\n",
       "128          ll         10\n",
       "135        didn          6\n",
       "136       doesn          6\n",
       "143        wasn          5\n",
       "168           \\          4\n",
       "170           ^          4\n",
       "138         isn          3\n",
       "171           _          3\n",
       "141        shan          2\n",
       "134    couldn't          1\n",
       "145      wouldn          1\n",
       "142     shouldn          1\n",
       "140       needn          1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words_punctuation_freq_pos = stop_words_punctuation_df.merge(Freq_words_count_pos, on = 'Word',how='inner')\n",
    "stop_words_punctuation_freq_pos.sort_values(by=['Frequency'],ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>the</td>\n",
       "      <td>259485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>159</td>\n",
       "      <td>,</td>\n",
       "      <td>209737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>161</td>\n",
       "      <td>.</td>\n",
       "      <td>186742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>a</td>\n",
       "      <td>126123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>and</td>\n",
       "      <td>117807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>of</td>\n",
       "      <td>109436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79</td>\n",
       "      <td>to</td>\n",
       "      <td>108890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>162</td>\n",
       "      <td>/</td>\n",
       "      <td>82883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>167</td>\n",
       "      <td>&gt;</td>\n",
       "      <td>82841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>165</td>\n",
       "      <td>&lt;</td>\n",
       "      <td>82771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>is</td>\n",
       "      <td>82080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>it</td>\n",
       "      <td>75247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>i</td>\n",
       "      <td>73781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>83</td>\n",
       "      <td>in</td>\n",
       "      <td>69323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>this</td>\n",
       "      <td>64528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>that</td>\n",
       "      <td>58801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>was</td>\n",
       "      <td>43795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67</td>\n",
       "      <td>for</td>\n",
       "      <td>34108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>but</td>\n",
       "      <td>34058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68</td>\n",
       "      <td>with</td>\n",
       "      <td>33217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>as</td>\n",
       "      <td>32368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>you</td>\n",
       "      <td>28297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>156</td>\n",
       "      <td>)</td>\n",
       "      <td>27603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85</td>\n",
       "      <td>on</td>\n",
       "      <td>26937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>155</td>\n",
       "      <td>(</td>\n",
       "      <td>26729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>111</td>\n",
       "      <td>not</td>\n",
       "      <td>26402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>have</td>\n",
       "      <td>24925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>are</td>\n",
       "      <td>24210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>be</td>\n",
       "      <td>22718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>he</td>\n",
       "      <td>21530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>they</td>\n",
       "      <td>20701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>149</td>\n",
       "      <td>!</td>\n",
       "      <td>20508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>at</td>\n",
       "      <td>19377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>his</td>\n",
       "      <td>18953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>all</td>\n",
       "      <td>18485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>168</td>\n",
       "      <td>?</td>\n",
       "      <td>17936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>115</td>\n",
       "      <td>so</td>\n",
       "      <td>17441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>94</td>\n",
       "      <td>there</td>\n",
       "      <td>16836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>123</td>\n",
       "      <td>just</td>\n",
       "      <td>16725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>by</td>\n",
       "      <td>16486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>an</td>\n",
       "      <td>16260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>do</td>\n",
       "      <td>16245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>or</td>\n",
       "      <td>16010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>from</td>\n",
       "      <td>15695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>who</td>\n",
       "      <td>15626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>if</td>\n",
       "      <td>15343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69</td>\n",
       "      <td>about</td>\n",
       "      <td>14109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84</td>\n",
       "      <td>out</td>\n",
       "      <td>13847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>what</td>\n",
       "      <td>13303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>107</td>\n",
       "      <td>some</td>\n",
       "      <td>13177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>109</td>\n",
       "      <td>no</td>\n",
       "      <td>12431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>has</td>\n",
       "      <td>12170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>her</td>\n",
       "      <td>12124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>when</td>\n",
       "      <td>10751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>112</td>\n",
       "      <td>only</td>\n",
       "      <td>10648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>104</td>\n",
       "      <td>more</td>\n",
       "      <td>10512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>81</td>\n",
       "      <td>up</td>\n",
       "      <td>10234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>were</td>\n",
       "      <td>9957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>she</td>\n",
       "      <td>9944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>had</td>\n",
       "      <td>9800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>did</td>\n",
       "      <td>9765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>121</td>\n",
       "      <td>can</td>\n",
       "      <td>9593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>my</td>\n",
       "      <td>9479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>118</td>\n",
       "      <td>very</td>\n",
       "      <td>9239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>which</td>\n",
       "      <td>9052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>me</td>\n",
       "      <td>8780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>does</td>\n",
       "      <td>8558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>their</td>\n",
       "      <td>8426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>we</td>\n",
       "      <td>8238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>163</td>\n",
       "      <td>:</td>\n",
       "      <td>8151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>116</td>\n",
       "      <td>than</td>\n",
       "      <td>8098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>been</td>\n",
       "      <td>8015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>because</td>\n",
       "      <td>7751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>-</td>\n",
       "      <td>7643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>154</td>\n",
       "      <td>'</td>\n",
       "      <td>7424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>how</td>\n",
       "      <td>7396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>91</td>\n",
       "      <td>then</td>\n",
       "      <td>7344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>any</td>\n",
       "      <td>7208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72</td>\n",
       "      <td>into</td>\n",
       "      <td>7202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>106</td>\n",
       "      <td>other</td>\n",
       "      <td>6847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>them</td>\n",
       "      <td>6435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>117</td>\n",
       "      <td>too</td>\n",
       "      <td>6397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>105</td>\n",
       "      <td>most</td>\n",
       "      <td>6266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>122</td>\n",
       "      <td>will</td>\n",
       "      <td>6204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>him</td>\n",
       "      <td>5998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76</td>\n",
       "      <td>after</td>\n",
       "      <td>5909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>its</td>\n",
       "      <td>5607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97</td>\n",
       "      <td>why</td>\n",
       "      <td>5475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>being</td>\n",
       "      <td>5337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>your</td>\n",
       "      <td>5186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>86</td>\n",
       "      <td>off</td>\n",
       "      <td>5177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>where</td>\n",
       "      <td>5165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>164</td>\n",
       "      <td>;</td>\n",
       "      <td>4950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>126</td>\n",
       "      <td>should</td>\n",
       "      <td>4825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>93</td>\n",
       "      <td>here</td>\n",
       "      <td>4454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>87</td>\n",
       "      <td>over</td>\n",
       "      <td>4394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>these</td>\n",
       "      <td>4344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73</td>\n",
       "      <td>through</td>\n",
       "      <td>3959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>108</td>\n",
       "      <td>such</td>\n",
       "      <td>3926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63</td>\n",
       "      <td>while</td>\n",
       "      <td>3817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>those</td>\n",
       "      <td>3518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>153</td>\n",
       "      <td>&amp;</td>\n",
       "      <td>3482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>127</td>\n",
       "      <td>now</td>\n",
       "      <td>3470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>103</td>\n",
       "      <td>few</td>\n",
       "      <td>3374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>before</td>\n",
       "      <td>3314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>114</td>\n",
       "      <td>same</td>\n",
       "      <td>3264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82</td>\n",
       "      <td>down</td>\n",
       "      <td>2939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>89</td>\n",
       "      <td>again</td>\n",
       "      <td>2776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>am</td>\n",
       "      <td>2480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71</td>\n",
       "      <td>between</td>\n",
       "      <td>2214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>113</td>\n",
       "      <td>own</td>\n",
       "      <td>1989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>having</td>\n",
       "      <td>1979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>101</td>\n",
       "      <td>both</td>\n",
       "      <td>1936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>92</td>\n",
       "      <td>once</td>\n",
       "      <td>1649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>our</td>\n",
       "      <td>1643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74</td>\n",
       "      <td>during</td>\n",
       "      <td>1586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>102</td>\n",
       "      <td>each</td>\n",
       "      <td>1534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>himself</td>\n",
       "      <td>1432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>doing</td>\n",
       "      <td>1424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>itself</td>\n",
       "      <td>1281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62</td>\n",
       "      <td>until</td>\n",
       "      <td>1279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>myself</td>\n",
       "      <td>1052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>against</td>\n",
       "      <td>1002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88</td>\n",
       "      <td>under</td>\n",
       "      <td>996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>themselves</td>\n",
       "      <td>899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>151</td>\n",
       "      <td>$</td>\n",
       "      <td>893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>yourself</td>\n",
       "      <td>831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>`</td>\n",
       "      <td>803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>nor</td>\n",
       "      <td>604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77</td>\n",
       "      <td>above</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>herself</td>\n",
       "      <td>499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>119</td>\n",
       "      <td>s</td>\n",
       "      <td>464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>whom</td>\n",
       "      <td>435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>further</td>\n",
       "      <td>425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>152</td>\n",
       "      <td>%</td>\n",
       "      <td>375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>157</td>\n",
       "      <td>*</td>\n",
       "      <td>309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>t</td>\n",
       "      <td>298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78</td>\n",
       "      <td>below</td>\n",
       "      <td>287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>#</td>\n",
       "      <td>283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>124</td>\n",
       "      <td>don</td>\n",
       "      <td>277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>147</td>\n",
       "      <td>won</td>\n",
       "      <td>232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>128</td>\n",
       "      <td>d</td>\n",
       "      <td>174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>131</td>\n",
       "      <td>o</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>m</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>172</td>\n",
       "      <td>]</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>[</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>ourselves</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>169</td>\n",
       "      <td>@</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>178</td>\n",
       "      <td>~</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>166</td>\n",
       "      <td>=</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>132</td>\n",
       "      <td>re</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>158</td>\n",
       "      <td>+</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>hers</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>yours</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>176</td>\n",
       "      <td>{</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>177</td>\n",
       "      <td>}</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>129</td>\n",
       "      <td>ll</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>yourselves</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>133</td>\n",
       "      <td>ve</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>theirs</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>144</td>\n",
       "      <td>ma</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>134</td>\n",
       "      <td>y</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>ours</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>138</td>\n",
       "      <td>didn</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>142</td>\n",
       "      <td>haven</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>173</td>\n",
       "      <td>^</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>139</td>\n",
       "      <td>doesn</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>146</td>\n",
       "      <td>wasn</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>137</td>\n",
       "      <td>couldn</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>143</td>\n",
       "      <td>isn</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>174</td>\n",
       "      <td>_</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>148</td>\n",
       "      <td>wouldn</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>141</td>\n",
       "      <td>hasn</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>135</td>\n",
       "      <td>ain</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>171</td>\n",
       "      <td>\\</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>hadn</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>don't</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>145</td>\n",
       "      <td>shan</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>136</td>\n",
       "      <td>aren</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Word  Frequency\n",
       "55          the     259485\n",
       "159           ,     209737\n",
       "161           .     186742\n",
       "53            a     126123\n",
       "56          and     117807\n",
       "64           of     109436\n",
       "79           to     108890\n",
       "162           /      82883\n",
       "167           >      82841\n",
       "165           <      82771\n",
       "38           is      82080\n",
       "21           it      75247\n",
       "0             i      73781\n",
       "83           in      69323\n",
       "33         this      64528\n",
       "34         that      58801\n",
       "40          was      43795\n",
       "67          for      34108\n",
       "57          but      34058\n",
       "68         with      33217\n",
       "61           as      32368\n",
       "8           you      28297\n",
       "156           )      27603\n",
       "85           on      26937\n",
       "155           (      26729\n",
       "111         not      26402\n",
       "45         have      24925\n",
       "39          are      24210\n",
       "42           be      22718\n",
       "13           he      21530\n",
       "24         they      20701\n",
       "149           !      20508\n",
       "65           at      19377\n",
       "15          his      18953\n",
       "99          all      18485\n",
       "168           ?      17936\n",
       "115          so      17441\n",
       "94        there      16836\n",
       "123        just      16725\n",
       "66           by      16486\n",
       "54           an      16260\n",
       "49           do      16245\n",
       "59           or      16010\n",
       "80         from      15695\n",
       "31          who      15626\n",
       "58           if      15343\n",
       "69        about      14109\n",
       "84          out      13847\n",
       "29         what      13303\n",
       "107        some      13177\n",
       "109          no      12431\n",
       "46          has      12170\n",
       "18          her      12124\n",
       "95         when      10751\n",
       "112        only      10648\n",
       "104        more      10512\n",
       "81           up      10234\n",
       "41         were       9957\n",
       "17          she       9944\n",
       "47          had       9800\n",
       "51          did       9765\n",
       "121         can       9593\n",
       "2            my       9479\n",
       "118        very       9239\n",
       "30        which       9052\n",
       "1            me       8780\n",
       "50         does       8558\n",
       "26        their       8426\n",
       "4            we       8238\n",
       "163           :       8151\n",
       "116        than       8098\n",
       "43         been       8015\n",
       "60      because       7751\n",
       "160           -       7643\n",
       "154           '       7424\n",
       "98          how       7396\n",
       "91         then       7344\n",
       "100         any       7208\n",
       "72         into       7202\n",
       "106       other       6847\n",
       "25         them       6435\n",
       "117         too       6397\n",
       "105        most       6266\n",
       "122        will       6204\n",
       "14          him       5998\n",
       "76        after       5909\n",
       "22          its       5607\n",
       "97          why       5475\n",
       "44        being       5337\n",
       "9          your       5186\n",
       "86          off       5177\n",
       "96        where       5165\n",
       "164           ;       4950\n",
       "126      should       4825\n",
       "93         here       4454\n",
       "87         over       4394\n",
       "35        these       4344\n",
       "73      through       3959\n",
       "108        such       3926\n",
       "63        while       3817\n",
       "36        those       3518\n",
       "153           &       3482\n",
       "127         now       3470\n",
       "103         few       3374\n",
       "75       before       3314\n",
       "114        same       3264\n",
       "82         down       2939\n",
       "89        again       2776\n",
       "37           am       2480\n",
       "71      between       2214\n",
       "113         own       1989\n",
       "48       having       1979\n",
       "101        both       1936\n",
       "92         once       1649\n",
       "5           our       1643\n",
       "74       during       1586\n",
       "102        each       1534\n",
       "16      himself       1432\n",
       "52        doing       1424\n",
       "23       itself       1281\n",
       "62        until       1279\n",
       "3        myself       1052\n",
       "70      against       1002\n",
       "88        under        996\n",
       "28   themselves        899\n",
       "151           $        893\n",
       "11     yourself        831\n",
       "175           `        803\n",
       "110         nor        604\n",
       "77        above        600\n",
       "20      herself        499\n",
       "119           s        464\n",
       "32         whom        435\n",
       "90      further        425\n",
       "152           %        375\n",
       "157           *        309\n",
       "120           t        298\n",
       "78        below        287\n",
       "150           #        283\n",
       "124         don        277\n",
       "147         won        232\n",
       "128           d        174\n",
       "131           o        123\n",
       "130           m        101\n",
       "172           ]         94\n",
       "170           [         91\n",
       "7     ourselves         88\n",
       "169           @         85\n",
       "178           ~         80\n",
       "166           =         79\n",
       "132          re         60\n",
       "158           +         52\n",
       "19         hers         47\n",
       "10        yours         42\n",
       "176           {         40\n",
       "177           }         39\n",
       "129          ll         39\n",
       "12   yourselves         36\n",
       "133          ve         34\n",
       "27       theirs         29\n",
       "144          ma         23\n",
       "134           y         22\n",
       "6          ours         20\n",
       "138        didn         17\n",
       "142       haven         17\n",
       "173           ^         13\n",
       "139       doesn         11\n",
       "146        wasn         10\n",
       "137      couldn         10\n",
       "143         isn         10\n",
       "174           _          6\n",
       "148      wouldn          6\n",
       "141        hasn          4\n",
       "135         ain          3\n",
       "171           \\          2\n",
       "140        hadn          2\n",
       "125       don't          1\n",
       "145        shan          1\n",
       "136        aren          1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words_punctuation_freq_neg = stop_words_punctuation_df.merge(Freq_words_count_neg, on = 'Word',how='inner')\n",
    "stop_words_punctuation_freq_neg.sort_values(by=['Frequency'],ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Frequency_x</th>\n",
       "      <th>Frequency_y</th>\n",
       "      <th>Difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>and</td>\n",
       "      <td>117807</td>\n",
       "      <td>140333</td>\n",
       "      <td>22526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>153</td>\n",
       "      <td>,</td>\n",
       "      <td>209737</td>\n",
       "      <td>225413</td>\n",
       "      <td>15676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>155</td>\n",
       "      <td>.</td>\n",
       "      <td>186742</td>\n",
       "      <td>171531</td>\n",
       "      <td>15211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>i</td>\n",
       "      <td>73781</td>\n",
       "      <td>61740</td>\n",
       "      <td>12041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>this</td>\n",
       "      <td>64528</td>\n",
       "      <td>52885</td>\n",
       "      <td>11643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>of</td>\n",
       "      <td>109436</td>\n",
       "      <td>120744</td>\n",
       "      <td>11308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>the</td>\n",
       "      <td>259485</td>\n",
       "      <td>269949</td>\n",
       "      <td>10464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>162</td>\n",
       "      <td>?</td>\n",
       "      <td>17936</td>\n",
       "      <td>7681</td>\n",
       "      <td>10255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>83</td>\n",
       "      <td>in</td>\n",
       "      <td>69323</td>\n",
       "      <td>78446</td>\n",
       "      <td>9123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>is</td>\n",
       "      <td>82080</td>\n",
       "      <td>91082</td>\n",
       "      <td>9002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>as</td>\n",
       "      <td>32368</td>\n",
       "      <td>40486</td>\n",
       "      <td>8118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>was</td>\n",
       "      <td>43795</td>\n",
       "      <td>35842</td>\n",
       "      <td>7953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>his</td>\n",
       "      <td>18953</td>\n",
       "      <td>26823</td>\n",
       "      <td>7870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>123</td>\n",
       "      <td>just</td>\n",
       "      <td>16725</td>\n",
       "      <td>11133</td>\n",
       "      <td>5592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>109</td>\n",
       "      <td>no</td>\n",
       "      <td>12431</td>\n",
       "      <td>7047</td>\n",
       "      <td>5384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>they</td>\n",
       "      <td>20701</td>\n",
       "      <td>15322</td>\n",
       "      <td>5379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>do</td>\n",
       "      <td>16245</td>\n",
       "      <td>11320</td>\n",
       "      <td>4925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>have</td>\n",
       "      <td>24925</td>\n",
       "      <td>20276</td>\n",
       "      <td>4649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79</td>\n",
       "      <td>to</td>\n",
       "      <td>108890</td>\n",
       "      <td>104265</td>\n",
       "      <td>4625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>161</td>\n",
       "      <td>&gt;</td>\n",
       "      <td>82841</td>\n",
       "      <td>78355</td>\n",
       "      <td>4486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>159</td>\n",
       "      <td>&lt;</td>\n",
       "      <td>82771</td>\n",
       "      <td>78310</td>\n",
       "      <td>4461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>156</td>\n",
       "      <td>/</td>\n",
       "      <td>82883</td>\n",
       "      <td>78481</td>\n",
       "      <td>4402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>94</td>\n",
       "      <td>there</td>\n",
       "      <td>16836</td>\n",
       "      <td>12456</td>\n",
       "      <td>4380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>if</td>\n",
       "      <td>15343</td>\n",
       "      <td>11391</td>\n",
       "      <td>3952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>a</td>\n",
       "      <td>126123</td>\n",
       "      <td>130072</td>\n",
       "      <td>3949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>or</td>\n",
       "      <td>16010</td>\n",
       "      <td>12065</td>\n",
       "      <td>3945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>that</td>\n",
       "      <td>58801</td>\n",
       "      <td>55015</td>\n",
       "      <td>3786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>118</td>\n",
       "      <td>very</td>\n",
       "      <td>9239</td>\n",
       "      <td>12910</td>\n",
       "      <td>3671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>he</td>\n",
       "      <td>21530</td>\n",
       "      <td>25102</td>\n",
       "      <td>3572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>be</td>\n",
       "      <td>22718</td>\n",
       "      <td>19308</td>\n",
       "      <td>3410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>111</td>\n",
       "      <td>not</td>\n",
       "      <td>26402</td>\n",
       "      <td>23071</td>\n",
       "      <td>3331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>115</td>\n",
       "      <td>so</td>\n",
       "      <td>17441</td>\n",
       "      <td>14132</td>\n",
       "      <td>3309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68</td>\n",
       "      <td>with</td>\n",
       "      <td>33217</td>\n",
       "      <td>36496</td>\n",
       "      <td>3279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>her</td>\n",
       "      <td>12124</td>\n",
       "      <td>15244</td>\n",
       "      <td>3120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>112</td>\n",
       "      <td>only</td>\n",
       "      <td>10648</td>\n",
       "      <td>7777</td>\n",
       "      <td>2871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>did</td>\n",
       "      <td>9765</td>\n",
       "      <td>6971</td>\n",
       "      <td>2794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97</td>\n",
       "      <td>why</td>\n",
       "      <td>5475</td>\n",
       "      <td>2793</td>\n",
       "      <td>2682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>any</td>\n",
       "      <td>7208</td>\n",
       "      <td>4729</td>\n",
       "      <td>2479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>by</td>\n",
       "      <td>16486</td>\n",
       "      <td>18963</td>\n",
       "      <td>2477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>has</td>\n",
       "      <td>12170</td>\n",
       "      <td>14574</td>\n",
       "      <td>2404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>who</td>\n",
       "      <td>15626</td>\n",
       "      <td>18001</td>\n",
       "      <td>2375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>149</td>\n",
       "      <td>(</td>\n",
       "      <td>26729</td>\n",
       "      <td>29034</td>\n",
       "      <td>2305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>were</td>\n",
       "      <td>9957</td>\n",
       "      <td>7702</td>\n",
       "      <td>2255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>91</td>\n",
       "      <td>then</td>\n",
       "      <td>7344</td>\n",
       "      <td>5249</td>\n",
       "      <td>2095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>122</td>\n",
       "      <td>will</td>\n",
       "      <td>6204</td>\n",
       "      <td>8154</td>\n",
       "      <td>1950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>you</td>\n",
       "      <td>28297</td>\n",
       "      <td>26367</td>\n",
       "      <td>1930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>)</td>\n",
       "      <td>27603</td>\n",
       "      <td>29499</td>\n",
       "      <td>1896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>but</td>\n",
       "      <td>34058</td>\n",
       "      <td>32310</td>\n",
       "      <td>1748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>107</td>\n",
       "      <td>some</td>\n",
       "      <td>13177</td>\n",
       "      <td>11439</td>\n",
       "      <td>1738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>143</td>\n",
       "      <td>!</td>\n",
       "      <td>20508</td>\n",
       "      <td>18834</td>\n",
       "      <td>1674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>86</td>\n",
       "      <td>off</td>\n",
       "      <td>5177</td>\n",
       "      <td>3536</td>\n",
       "      <td>1641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>had</td>\n",
       "      <td>9800</td>\n",
       "      <td>8195</td>\n",
       "      <td>1605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>at</td>\n",
       "      <td>19377</td>\n",
       "      <td>17813</td>\n",
       "      <td>1564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>101</td>\n",
       "      <td>both</td>\n",
       "      <td>1936</td>\n",
       "      <td>3486</td>\n",
       "      <td>1550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84</td>\n",
       "      <td>out</td>\n",
       "      <td>13847</td>\n",
       "      <td>12309</td>\n",
       "      <td>1538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>been</td>\n",
       "      <td>8015</td>\n",
       "      <td>6478</td>\n",
       "      <td>1537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>an</td>\n",
       "      <td>16260</td>\n",
       "      <td>17754</td>\n",
       "      <td>1494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>it</td>\n",
       "      <td>75247</td>\n",
       "      <td>73766</td>\n",
       "      <td>1481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>she</td>\n",
       "      <td>9944</td>\n",
       "      <td>11415</td>\n",
       "      <td>1471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>him</td>\n",
       "      <td>5998</td>\n",
       "      <td>7448</td>\n",
       "      <td>1450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>its</td>\n",
       "      <td>5607</td>\n",
       "      <td>7025</td>\n",
       "      <td>1418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>what</td>\n",
       "      <td>13303</td>\n",
       "      <td>11897</td>\n",
       "      <td>1406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>because</td>\n",
       "      <td>7751</td>\n",
       "      <td>6352</td>\n",
       "      <td>1399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>their</td>\n",
       "      <td>8426</td>\n",
       "      <td>9808</td>\n",
       "      <td>1382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>should</td>\n",
       "      <td>4825</td>\n",
       "      <td>3449</td>\n",
       "      <td>1376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>105</td>\n",
       "      <td>most</td>\n",
       "      <td>6266</td>\n",
       "      <td>7552</td>\n",
       "      <td>1286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>your</td>\n",
       "      <td>5186</td>\n",
       "      <td>3954</td>\n",
       "      <td>1232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>113</td>\n",
       "      <td>own</td>\n",
       "      <td>1989</td>\n",
       "      <td>3140</td>\n",
       "      <td>1151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69</td>\n",
       "      <td>about</td>\n",
       "      <td>14109</td>\n",
       "      <td>13031</td>\n",
       "      <td>1078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>102</td>\n",
       "      <td>each</td>\n",
       "      <td>1534</td>\n",
       "      <td>2587</td>\n",
       "      <td>1053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>104</td>\n",
       "      <td>more</td>\n",
       "      <td>10512</td>\n",
       "      <td>11531</td>\n",
       "      <td>1019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>81</td>\n",
       "      <td>up</td>\n",
       "      <td>10234</td>\n",
       "      <td>9223</td>\n",
       "      <td>1011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>117</td>\n",
       "      <td>too</td>\n",
       "      <td>6397</td>\n",
       "      <td>5421</td>\n",
       "      <td>976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>from</td>\n",
       "      <td>15695</td>\n",
       "      <td>16670</td>\n",
       "      <td>975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>148</td>\n",
       "      <td>'</td>\n",
       "      <td>7424</td>\n",
       "      <td>8372</td>\n",
       "      <td>948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67</td>\n",
       "      <td>for</td>\n",
       "      <td>34108</td>\n",
       "      <td>35051</td>\n",
       "      <td>943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>me</td>\n",
       "      <td>8780</td>\n",
       "      <td>7856</td>\n",
       "      <td>924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>158</td>\n",
       "      <td>;</td>\n",
       "      <td>4950</td>\n",
       "      <td>5832</td>\n",
       "      <td>882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>116</td>\n",
       "      <td>than</td>\n",
       "      <td>8098</td>\n",
       "      <td>7230</td>\n",
       "      <td>868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>how</td>\n",
       "      <td>7396</td>\n",
       "      <td>6545</td>\n",
       "      <td>851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>147</td>\n",
       "      <td>&amp;</td>\n",
       "      <td>3482</td>\n",
       "      <td>2639</td>\n",
       "      <td>843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71</td>\n",
       "      <td>between</td>\n",
       "      <td>2214</td>\n",
       "      <td>3055</td>\n",
       "      <td>841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>does</td>\n",
       "      <td>8558</td>\n",
       "      <td>7735</td>\n",
       "      <td>823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>157</td>\n",
       "      <td>:</td>\n",
       "      <td>8151</td>\n",
       "      <td>7390</td>\n",
       "      <td>761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>our</td>\n",
       "      <td>1643</td>\n",
       "      <td>2387</td>\n",
       "      <td>744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>all</td>\n",
       "      <td>18485</td>\n",
       "      <td>17803</td>\n",
       "      <td>682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>my</td>\n",
       "      <td>9479</td>\n",
       "      <td>10143</td>\n",
       "      <td>664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>106</td>\n",
       "      <td>other</td>\n",
       "      <td>6847</td>\n",
       "      <td>7474</td>\n",
       "      <td>627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85</td>\n",
       "      <td>on</td>\n",
       "      <td>26937</td>\n",
       "      <td>26331</td>\n",
       "      <td>606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>when</td>\n",
       "      <td>10751</td>\n",
       "      <td>11354</td>\n",
       "      <td>603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>them</td>\n",
       "      <td>6435</td>\n",
       "      <td>5867</td>\n",
       "      <td>568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63</td>\n",
       "      <td>while</td>\n",
       "      <td>3817</td>\n",
       "      <td>4346</td>\n",
       "      <td>529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>145</td>\n",
       "      <td>$</td>\n",
       "      <td>893</td>\n",
       "      <td>386</td>\n",
       "      <td>507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>which</td>\n",
       "      <td>9052</td>\n",
       "      <td>9541</td>\n",
       "      <td>489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>those</td>\n",
       "      <td>3518</td>\n",
       "      <td>4007</td>\n",
       "      <td>489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>93</td>\n",
       "      <td>here</td>\n",
       "      <td>4454</td>\n",
       "      <td>3990</td>\n",
       "      <td>464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>we</td>\n",
       "      <td>8238</td>\n",
       "      <td>8670</td>\n",
       "      <td>432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>103</td>\n",
       "      <td>few</td>\n",
       "      <td>3374</td>\n",
       "      <td>2950</td>\n",
       "      <td>424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>89</td>\n",
       "      <td>again</td>\n",
       "      <td>2776</td>\n",
       "      <td>3192</td>\n",
       "      <td>416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>doing</td>\n",
       "      <td>1424</td>\n",
       "      <td>1015</td>\n",
       "      <td>409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>himself</td>\n",
       "      <td>1432</td>\n",
       "      <td>1822</td>\n",
       "      <td>390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82</td>\n",
       "      <td>down</td>\n",
       "      <td>2939</td>\n",
       "      <td>2552</td>\n",
       "      <td>387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>are</td>\n",
       "      <td>24210</td>\n",
       "      <td>23828</td>\n",
       "      <td>382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>am</td>\n",
       "      <td>2480</td>\n",
       "      <td>2101</td>\n",
       "      <td>379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>being</td>\n",
       "      <td>5337</td>\n",
       "      <td>5023</td>\n",
       "      <td>314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>92</td>\n",
       "      <td>once</td>\n",
       "      <td>1649</td>\n",
       "      <td>1949</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>myself</td>\n",
       "      <td>1052</td>\n",
       "      <td>756</td>\n",
       "      <td>296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>87</td>\n",
       "      <td>over</td>\n",
       "      <td>4394</td>\n",
       "      <td>4111</td>\n",
       "      <td>283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62</td>\n",
       "      <td>until</td>\n",
       "      <td>1279</td>\n",
       "      <td>1539</td>\n",
       "      <td>260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73</td>\n",
       "      <td>through</td>\n",
       "      <td>3959</td>\n",
       "      <td>3708</td>\n",
       "      <td>251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>141</td>\n",
       "      <td>won</td>\n",
       "      <td>232</td>\n",
       "      <td>469</td>\n",
       "      <td>237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>where</td>\n",
       "      <td>5165</td>\n",
       "      <td>4929</td>\n",
       "      <td>236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74</td>\n",
       "      <td>during</td>\n",
       "      <td>1586</td>\n",
       "      <td>1816</td>\n",
       "      <td>230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>against</td>\n",
       "      <td>1002</td>\n",
       "      <td>1218</td>\n",
       "      <td>216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>119</td>\n",
       "      <td>s</td>\n",
       "      <td>464</td>\n",
       "      <td>253</td>\n",
       "      <td>211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>nor</td>\n",
       "      <td>604</td>\n",
       "      <td>397</td>\n",
       "      <td>207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76</td>\n",
       "      <td>after</td>\n",
       "      <td>5909</td>\n",
       "      <td>5707</td>\n",
       "      <td>202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72</td>\n",
       "      <td>into</td>\n",
       "      <td>7202</td>\n",
       "      <td>7001</td>\n",
       "      <td>201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>126</td>\n",
       "      <td>now</td>\n",
       "      <td>3470</td>\n",
       "      <td>3668</td>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>yourself</td>\n",
       "      <td>831</td>\n",
       "      <td>634</td>\n",
       "      <td>197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>these</td>\n",
       "      <td>4344</td>\n",
       "      <td>4147</td>\n",
       "      <td>197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>154</td>\n",
       "      <td>-</td>\n",
       "      <td>7643</td>\n",
       "      <td>7826</td>\n",
       "      <td>183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>151</td>\n",
       "      <td>*</td>\n",
       "      <td>309</td>\n",
       "      <td>131</td>\n",
       "      <td>178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>herself</td>\n",
       "      <td>499</td>\n",
       "      <td>677</td>\n",
       "      <td>178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>169</td>\n",
       "      <td>`</td>\n",
       "      <td>803</td>\n",
       "      <td>625</td>\n",
       "      <td>178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>whom</td>\n",
       "      <td>435</td>\n",
       "      <td>603</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78</td>\n",
       "      <td>below</td>\n",
       "      <td>287</td>\n",
       "      <td>120</td>\n",
       "      <td>167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>t</td>\n",
       "      <td>298</td>\n",
       "      <td>145</td>\n",
       "      <td>153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>114</td>\n",
       "      <td>same</td>\n",
       "      <td>3264</td>\n",
       "      <td>3123</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>having</td>\n",
       "      <td>1979</td>\n",
       "      <td>1862</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>144</td>\n",
       "      <td>#</td>\n",
       "      <td>283</td>\n",
       "      <td>180</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>108</td>\n",
       "      <td>such</td>\n",
       "      <td>3926</td>\n",
       "      <td>4021</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>121</td>\n",
       "      <td>can</td>\n",
       "      <td>9593</td>\n",
       "      <td>9499</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>itself</td>\n",
       "      <td>1281</td>\n",
       "      <td>1199</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77</td>\n",
       "      <td>above</td>\n",
       "      <td>600</td>\n",
       "      <td>680</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>171</td>\n",
       "      <td>}</td>\n",
       "      <td>39</td>\n",
       "      <td>107</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>{</td>\n",
       "      <td>40</td>\n",
       "      <td>106</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>146</td>\n",
       "      <td>%</td>\n",
       "      <td>375</td>\n",
       "      <td>320</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>172</td>\n",
       "      <td>~</td>\n",
       "      <td>80</td>\n",
       "      <td>29</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>ourselves</td>\n",
       "      <td>88</td>\n",
       "      <td>131</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>129</td>\n",
       "      <td>m</td>\n",
       "      <td>101</td>\n",
       "      <td>68</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>128</td>\n",
       "      <td>ll</td>\n",
       "      <td>39</td>\n",
       "      <td>10</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>127</td>\n",
       "      <td>d</td>\n",
       "      <td>174</td>\n",
       "      <td>146</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>124</td>\n",
       "      <td>don</td>\n",
       "      <td>277</td>\n",
       "      <td>251</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>138</td>\n",
       "      <td>ma</td>\n",
       "      <td>23</td>\n",
       "      <td>44</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>further</td>\n",
       "      <td>425</td>\n",
       "      <td>446</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>=</td>\n",
       "      <td>79</td>\n",
       "      <td>58</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>132</td>\n",
       "      <td>ve</td>\n",
       "      <td>34</td>\n",
       "      <td>13</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88</td>\n",
       "      <td>under</td>\n",
       "      <td>996</td>\n",
       "      <td>1015</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>131</td>\n",
       "      <td>re</td>\n",
       "      <td>60</td>\n",
       "      <td>43</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>163</td>\n",
       "      <td>@</td>\n",
       "      <td>85</td>\n",
       "      <td>69</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>yourselves</td>\n",
       "      <td>36</td>\n",
       "      <td>22</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>before</td>\n",
       "      <td>3314</td>\n",
       "      <td>3301</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>hers</td>\n",
       "      <td>47</td>\n",
       "      <td>58</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>134</td>\n",
       "      <td>didn</td>\n",
       "      <td>17</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>152</td>\n",
       "      <td>+</td>\n",
       "      <td>52</td>\n",
       "      <td>42</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>themselves</td>\n",
       "      <td>899</td>\n",
       "      <td>889</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>167</td>\n",
       "      <td>^</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>137</td>\n",
       "      <td>isn</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>164</td>\n",
       "      <td>[</td>\n",
       "      <td>91</td>\n",
       "      <td>85</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>135</td>\n",
       "      <td>doesn</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>142</td>\n",
       "      <td>wouldn</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>136</td>\n",
       "      <td>haven</td>\n",
       "      <td>17</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>133</td>\n",
       "      <td>y</td>\n",
       "      <td>22</td>\n",
       "      <td>27</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>yours</td>\n",
       "      <td>42</td>\n",
       "      <td>37</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>o</td>\n",
       "      <td>123</td>\n",
       "      <td>128</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>wasn</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>ours</td>\n",
       "      <td>20</td>\n",
       "      <td>24</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>166</td>\n",
       "      <td>]</td>\n",
       "      <td>94</td>\n",
       "      <td>91</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>168</td>\n",
       "      <td>_</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>165</td>\n",
       "      <td>\\</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>139</td>\n",
       "      <td>shan</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>theirs</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Word  Frequency_x  Frequency_y  Difference\n",
       "56          and       117807       140333       22526\n",
       "153           ,       209737       225413       15676\n",
       "155           .       186742       171531       15211\n",
       "0             i        73781        61740       12041\n",
       "33         this        64528        52885       11643\n",
       "64           of       109436       120744       11308\n",
       "55          the       259485       269949       10464\n",
       "162           ?        17936         7681       10255\n",
       "83           in        69323        78446        9123\n",
       "38           is        82080        91082        9002\n",
       "61           as        32368        40486        8118\n",
       "40          was        43795        35842        7953\n",
       "15          his        18953        26823        7870\n",
       "123        just        16725        11133        5592\n",
       "109          no        12431         7047        5384\n",
       "24         they        20701        15322        5379\n",
       "49           do        16245        11320        4925\n",
       "45         have        24925        20276        4649\n",
       "79           to       108890       104265        4625\n",
       "161           >        82841        78355        4486\n",
       "159           <        82771        78310        4461\n",
       "156           /        82883        78481        4402\n",
       "94        there        16836        12456        4380\n",
       "58           if        15343        11391        3952\n",
       "53            a       126123       130072        3949\n",
       "59           or        16010        12065        3945\n",
       "34         that        58801        55015        3786\n",
       "118        very         9239        12910        3671\n",
       "13           he        21530        25102        3572\n",
       "42           be        22718        19308        3410\n",
       "111         not        26402        23071        3331\n",
       "115          so        17441        14132        3309\n",
       "68         with        33217        36496        3279\n",
       "18          her        12124        15244        3120\n",
       "112        only        10648         7777        2871\n",
       "51          did         9765         6971        2794\n",
       "97          why         5475         2793        2682\n",
       "100         any         7208         4729        2479\n",
       "66           by        16486        18963        2477\n",
       "46          has        12170        14574        2404\n",
       "31          who        15626        18001        2375\n",
       "149           (        26729        29034        2305\n",
       "41         were         9957         7702        2255\n",
       "91         then         7344         5249        2095\n",
       "122        will         6204         8154        1950\n",
       "8           you        28297        26367        1930\n",
       "150           )        27603        29499        1896\n",
       "57          but        34058        32310        1748\n",
       "107        some        13177        11439        1738\n",
       "143           !        20508        18834        1674\n",
       "86          off         5177         3536        1641\n",
       "47          had         9800         8195        1605\n",
       "65           at        19377        17813        1564\n",
       "101        both         1936         3486        1550\n",
       "84          out        13847        12309        1538\n",
       "43         been         8015         6478        1537\n",
       "54           an        16260        17754        1494\n",
       "21           it        75247        73766        1481\n",
       "17          she         9944        11415        1471\n",
       "14          him         5998         7448        1450\n",
       "22          its         5607         7025        1418\n",
       "29         what        13303        11897        1406\n",
       "60      because         7751         6352        1399\n",
       "26        their         8426         9808        1382\n",
       "125      should         4825         3449        1376\n",
       "105        most         6266         7552        1286\n",
       "9          your         5186         3954        1232\n",
       "113         own         1989         3140        1151\n",
       "69        about        14109        13031        1078\n",
       "102        each         1534         2587        1053\n",
       "104        more        10512        11531        1019\n",
       "81           up        10234         9223        1011\n",
       "117         too         6397         5421         976\n",
       "80         from        15695        16670         975\n",
       "148           '         7424         8372         948\n",
       "67          for        34108        35051         943\n",
       "1            me         8780         7856         924\n",
       "158           ;         4950         5832         882\n",
       "116        than         8098         7230         868\n",
       "98          how         7396         6545         851\n",
       "147           &         3482         2639         843\n",
       "71      between         2214         3055         841\n",
       "50         does         8558         7735         823\n",
       "157           :         8151         7390         761\n",
       "5           our         1643         2387         744\n",
       "99          all        18485        17803         682\n",
       "2            my         9479        10143         664\n",
       "106       other         6847         7474         627\n",
       "85           on        26937        26331         606\n",
       "95         when        10751        11354         603\n",
       "25         them         6435         5867         568\n",
       "63        while         3817         4346         529\n",
       "145           $          893          386         507\n",
       "30        which         9052         9541         489\n",
       "36        those         3518         4007         489\n",
       "93         here         4454         3990         464\n",
       "4            we         8238         8670         432\n",
       "103         few         3374         2950         424\n",
       "89        again         2776         3192         416\n",
       "52        doing         1424         1015         409\n",
       "16      himself         1432         1822         390\n",
       "82         down         2939         2552         387\n",
       "39          are        24210        23828         382\n",
       "37           am         2480         2101         379\n",
       "44        being         5337         5023         314\n",
       "92         once         1649         1949         300\n",
       "3        myself         1052          756         296\n",
       "87         over         4394         4111         283\n",
       "62        until         1279         1539         260\n",
       "73      through         3959         3708         251\n",
       "141         won          232          469         237\n",
       "96        where         5165         4929         236\n",
       "74       during         1586         1816         230\n",
       "70      against         1002         1218         216\n",
       "119           s          464          253         211\n",
       "110         nor          604          397         207\n",
       "76        after         5909         5707         202\n",
       "72         into         7202         7001         201\n",
       "126         now         3470         3668         198\n",
       "11     yourself          831          634         197\n",
       "35        these         4344         4147         197\n",
       "154           -         7643         7826         183\n",
       "151           *          309          131         178\n",
       "20      herself          499          677         178\n",
       "169           `          803          625         178\n",
       "32         whom          435          603         168\n",
       "78        below          287          120         167\n",
       "120           t          298          145         153\n",
       "114        same         3264         3123         141\n",
       "48       having         1979         1862         117\n",
       "144           #          283          180         103\n",
       "108        such         3926         4021          95\n",
       "121         can         9593         9499          94\n",
       "23       itself         1281         1199          82\n",
       "77        above          600          680          80\n",
       "171           }           39          107          68\n",
       "170           {           40          106          66\n",
       "146           %          375          320          55\n",
       "172           ~           80           29          51\n",
       "7     ourselves           88          131          43\n",
       "129           m          101           68          33\n",
       "128          ll           39           10          29\n",
       "127           d          174          146          28\n",
       "124         don          277          251          26\n",
       "138          ma           23           44          21\n",
       "90      further          425          446          21\n",
       "160           =           79           58          21\n",
       "132          ve           34           13          21\n",
       "88        under          996         1015          19\n",
       "131          re           60           43          17\n",
       "163           @           85           69          16\n",
       "12   yourselves           36           22          14\n",
       "75       before         3314         3301          13\n",
       "19         hers           47           58          11\n",
       "134        didn           17            6          11\n",
       "152           +           52           42          10\n",
       "28   themselves          899          889          10\n",
       "167           ^           13            4           9\n",
       "137         isn           10            3           7\n",
       "164           [           91           85           6\n",
       "135       doesn           11            6           5\n",
       "142      wouldn            6            1           5\n",
       "136       haven           17           12           5\n",
       "133           y           22           27           5\n",
       "10        yours           42           37           5\n",
       "130           o          123          128           5\n",
       "140        wasn           10            5           5\n",
       "6          ours           20           24           4\n",
       "166           ]           94           91           3\n",
       "168           _            6            3           3\n",
       "165           \\            2            4           2\n",
       "139        shan            1            2           1\n",
       "27       theirs           29           29           0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words_punctuation_freq_comp_ngpos=stop_words_punctuation_freq_neg.merge(stop_words_punctuation_freq_pos, on = 'Word',how='inner')\n",
    "stop_words_punctuation_freq_comp_ngpos['Difference'] = abs(stop_words_punctuation_freq_comp_ngpos['Frequency_x'] - stop_words_punctuation_freq_comp_ngpos['Frequency_y'])\n",
    "stop_words_punctuation_freq_comp_ngpos.sort_values(by=['Difference'],ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 2 "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "2) Data Cleaning - Storing training data of different methods of cleaning and impact of data cleaning on logistic                              regression\n",
    "             i) tokenisation + stemming\n",
    "            ii) tokenisation + lemmatization\n",
    "           iii) tokenisation + data cleaning of specific types of features : stop words , numbers , punctuation ,POS tags\n",
    "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building different sets of data\n",
    "all_text = pd.DataFrame()\n",
    "all_text['text'] = raw_data['text']\n",
    "all_lables = raw_data['sentiment'].tolist()\n",
    "# Set 1 : lemmatized data\n",
    "# Set 2 : Stemmed data\n",
    "import nltk\n",
    "import string\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "from nltk.stem.porter import *\n",
    "from nltk.tokenize import word_tokenize\n",
    "ps_stemmer = PorterStemmer()\n",
    "all_text['text_tokenized']=all_text['text'].apply(nltk.word_tokenize)\n",
    "all_text['text_lemmatized']=all_text['text'].apply(nltk.word_tokenize).apply(lambda row: list(wordnet_lemmatizer.lemmatize(row[row.index(y)].lower()) for y in row))\n",
    "all_text['text_stemmed']=all_text['text'].apply(nltk.word_tokenize).apply(lambda row: list(ps_stemmer.stem(row[row.index(y)].lower()) for y in row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_text['text_tokenized_stopwordspunctnum_removal'] = all_text['text_tokenized']\n",
    "all_text['text_lemmatized_stopwordspunctnum_removal'] = all_text['text_lemmatized']\n",
    "all_text['text_stemmed_stopwordspunctnum_removal'] = all_text['text_stemmed']       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "def word_removal(data):\n",
    "    for i in range(0,35000):\n",
    "        for word in data[i]:\n",
    "            if word in string.punctuation: # remove all punctuations\n",
    "                data[i].remove(word)\n",
    "            elif word in stop_words:\n",
    "                data[i].remove(word)\n",
    "            elif (word.isnumeric() == True):\n",
    "                data[i].remove(word)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_text['text_tokenized_stopwordspunctnum_removal'] = word_removal(all_text['text_tokenized_stopwordspunctnum_removal'])\n",
    "all_text['text_lemmatized_stopwordspunctnum_removal'] = word_removal(all_text['text_lemmatized_stopwordspunctnum_removal'])\n",
    "all_text['text_stemmed_stopwordspunctnum_removal'] = word_removal(all_text['text_stemmed_stopwordspunctnum_removal'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text_tokenized =[\" \".join(review) for review in all_text['text_tokenized'][:35000].values]\n",
    "train_text_lemmatized =[\" \".join(review) for review in all_text['text_lemmatized'][:35000].values]\n",
    "train_text_stemmed =[\" \".join(review) for review in all_text['text_stemmed'][:35000].values]\n",
    "train_text_tokenized_stopwordspunctnum_removal =[\" \".join(review) for review in all_text['text_tokenized_stopwordspunctnum_removal'][:35000].values]\n",
    "train_text_lemmatized_stopwordspunctnum_removal =[\" \".join(review) for review in all_text['text_lemmatized_stopwordspunctnum_removal'][:35000].values]\n",
    "train_text_stemmed_stopwordspunctnum_removal =[\" \".join(review) for review in all_text['text_stemmed_stopwordspunctnum_removal'][:35000].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconds_Re\\lib\\site-packages\\ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "## POS TAGS \n",
    "#### removing numbers and punctuations and others using spacy\n",
    "import spacy\n",
    "words_withpos = pd.DataFrame(columns = ['word','ent.text', 'ent.start_char', 'ent.end_char', 'ent.label_','token.text', 'token.lemma_', 'token.pos_', 'token.tag_', 'token.dep_',\n",
    "             'token.shape_','token.is_alpha', 'token.is_stop'])\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "for i in range(0,35000):\n",
    "    doc = nlp(train_text[i])\n",
    "    for ent in doc.ents:\n",
    "        words_withpos[['word','ent.text', 'ent.start_char', 'ent.end_char', 'ent.label_']][i] = (word,ent.text, ent.start_char, ent.end_char, ent.label_)\n",
    "\n",
    "# for ent in doc.ents:\n",
    "#     (ent.text, ent.start_char, ent.end_char, ent.label_)\n",
    "# for token in doc:\n",
    "#     print(token.text, token.lemma_, token.pos_, token.tag_, token.dep_,\n",
    "#             token.shape_, token.is_alpha, token.is_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], Name: ent.text, dtype: object)\n"
     ]
    }
   ],
   "source": [
    "print(words_withpos['ent.text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "for i in range(0,35000):\n",
    "    for (word,pos) in nltk.pos_tag(all_text['text'][i]):\n",
    "        if not ((pos.startswith('JJ')) or pos.startswith('RB')):or (pos.startswith('NN')) \n",
    "            all_text['text'][i].remove(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data split. \n",
    "train_text =[\"\".join(review) for review in feature_df['Word'][:35000].values]\n",
    "train_labels = all_lables[:35000]\n",
    "test_text = [\" \".join(review) for review in all_text['text'][35000:].values]\n",
    "test_labels = all_lables[35000:]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# let us try just using tfid vectorizer and logistic regression and varying the hyperparameters using Gridsearch CV \n",
    "# The grid search was taking a very long time, I tried multiple combinations. This combination gave a 91.2% accuracy 5 fold cross\n",
    "# validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter (CV score=0.912):\n",
      "[('tfidf', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
      "                input='content', lowercase=True, max_df=20000,\n",
      "                max_features=None, min_df=1, ngram_range=(1, 2), norm='l2',\n",
      "                preprocessor=None, smooth_idf=True, stop_words=None,\n",
      "                strip_accents=None, sublinear_tf=False,\n",
      "                token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "                vocabulary=None)), ('clf', LogisticRegression(C=10000.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='saga', tol=0.0001, verbose=0,\n",
      "                   warm_start=False))]\n"
     ]
    }
   ],
   "source": [
    "# print(grid_search_tune.grid_scores_)\n",
    "print(\"Best parameter (CV score=%0.3f):\" % grid_search_tune.best_score_)\n",
    "print(grid_search_tune.best_estimator_.steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "#for i in range(1,35000,1000):\n",
    "#max_feature_num = 1000\n",
    "def logistic(train_data,test_data,train_labels,test_labels):\n",
    "    train_vectorizer = TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
    "                encoding='utf-8',input='content', lowercase=True, max_df=20000,\n",
    "                max_features=None, min_df=1, ngram_range=(1, 2), norm='l2',\n",
    "                preprocessor=None, smooth_idf=True, stop_words=None,\n",
    "                strip_accents=None, sublinear_tf=False,\n",
    "                token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True)\n",
    "    train_vecs = train_vectorizer.fit_transform(train_text)\n",
    "    test_vecs = TfidfVectorizer(vocabulary=train_vectorizer.vocabulary_).fit_transform(test_text)\n",
    "\n",
    "# train model\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    clf = LogisticRegression(C=10000.0, class_weight=None, dual=False, fit_intercept=True,\n",
    "                   intercept_scaling=1, l1_ratio=None, max_iter=10000,\n",
    "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
    "                   random_state=None, solver='saga', tol=0.0001, verbose=0,\n",
    "                   warm_start=False).fit(train_vecs, train_labels)\n",
    "\n",
    "# test model\n",
    "    test_pred = clf.predict(test_vecs)\n",
    "    from sklearn.metrics import precision_recall_fscore_support,accuracy_score\n",
    "    acc = accuracy_score(test_labels, test_pred)\n",
    "    pre, rec, f1, _ = precision_recall_fscore_support(test_labels, test_pred, average='macro')\n",
    "    # print(max_feature_num)\n",
    "    print('acc', acc)\n",
    "    print('precision', pre)\n",
    "    print('rec', rec)\n",
    "    print('f1', f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_text_tokenized\n",
      "acc 0.89\n",
      "precision 0.8899993855858439\n",
      "rec 0.8899966399462391\n",
      "f1 0.8899978703587701\n",
      "train_text_lemmatized\n",
      "acc 0.889\n",
      "precision 0.8890072690598609\n",
      "rec 0.8889910238563816\n",
      "f1 0.8889962658343826\n",
      "train_text_stemmed\n",
      "acc 0.891\n",
      "precision 0.8910020760747387\n",
      "rec 0.8909942559080946\n",
      "f1 0.8909972749318733\n",
      "train_text_tokenized_stopwordspunctnum_removal\n",
      "acc 0.891\n",
      "precision 0.8910044800471574\n",
      "rec 0.8909926558824941\n",
      "f1 0.8909968214673141\n",
      "train_text_lemmatized_stopwordspunctnum_removal\n",
      "acc 0.8908\n",
      "precision 0.8908010555211012\n",
      "rec 0.8907950527208435\n",
      "f1 0.8907974839740307\n",
      "train_text_stemmed_stopwordspunctnum_removal\n",
      "acc 0.89\n",
      "precision 0.8900031745300288\n",
      "rec 0.8899934398950383\n",
      "f1 0.88999702551957\n"
     ]
    }
   ],
   "source": [
    "# Table of results \n",
    "print(\"train_text_tokenized\")\n",
    "logistic(train_text_tokenized,test_text,train_labels,test_labels)\n",
    "print(\"train_text_lemmatized\")\n",
    "logistic(train_text_lemmatized,test_text,train_labels,test_labels)\n",
    "print(\"train_text_stemmed\")\n",
    "logistic(train_text_stemmed,test_text,train_labels,test_labels)\n",
    "print(\"train_text_tokenized_stopwordspunctnum_removal\")\n",
    "logistic(train_text_tokenized_stopwordspunctnum_removal,test_text,train_labels,test_labels)\n",
    "print(\"train_text_lemmatized_stopwordspunctnum_removal\")\n",
    "logistic(train_text_lemmatized_stopwordspunctnum_removal,test_text,train_labels,test_labels)\n",
    "print(\"train_text_stemmed_stopwordspunctnum_removal\")\n",
    "logistic(train_text_stemmed_stopwordspunctnum_removal,test_text,train_labels,test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "pipeline = Pipeline([('tfidf', TfidfVectorizer(lowercase=True,max_df= 20000,stop_words = None)),('clf', LogisticRegression(solver='saga',max_iter=10000))])\n",
    "param_grid = {\n",
    "    \n",
    "    'tfidf__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
    "    'clf__C': np.logspace(-4, 4, 4)\n",
    "    \n",
    "}\n",
    "grid_search_tune = GridSearchCV(pipeline, param_grid,cv=5,verbose=2,n_jobs=-1)\n",
    "grid_search_tune.fit(train_text, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_singleword(train_data,test_data,train_labels,test_labels):\n",
    "    train_vectorizer = TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
    "                encoding='utf-8',input='content', lowercase=True, max_df=20000,\n",
    "                max_features=None, min_df=1, ngram_range=False, norm='l2',\n",
    "                preprocessor=None, smooth_idf=True, stop_words=None,\n",
    "                strip_accents=None, sublinear_tf=False,\n",
    "                token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True)\n",
    "    train_vecs = train_vectorizer.fit_transform(train_text)\n",
    "    test_vecs = TfidfVectorizer(vocabulary=train_vectorizer.vocabulary_).fit_transform(test_text)\n",
    "\n",
    "# train model\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    clf = LogisticRegression(C=10000.0, class_weight=None, dual=False, fit_intercept=True,\n",
    "                   intercept_scaling=1, l1_ratio=None, max_iter=10000,\n",
    "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
    "                   random_state=None, solver='saga', tol=0.0001, verbose=0,\n",
    "                   warm_start=False).fit(train_vecs, train_labels)\n",
    "\n",
    "# test model\n",
    "    test_pred = clf.predict(test_vecs)\n",
    "    from sklearn.metrics import precision_recall_fscore_support,accuracy_score\n",
    "    acc = accuracy_score(test_labels, test_pred)\n",
    "    pre, rec, f1, _ = precision_recall_fscore_support(test_labels, test_pred, average='macro')\n",
    "    # print(max_feature_num)\n",
    "    print('acc', acc)\n",
    "    print('precision', pre)\n",
    "    print('rec', rec)\n",
    "    print('f1', f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table of results \n",
    "print(\"train_text_tokenized\")\n",
    "logistic_singleword(train_text_tokenized,test_text,train_labels,test_labels)\n",
    "print(\"train_text_lemmatized\")\n",
    "logistic_singleword(train_text_lemmatized,test_text,train_labels,test_labels)\n",
    "print(\"train_text_stemmed\")\n",
    "logistic_singleword(train_text_stemmed,test_text,train_labels,test_labels)\n",
    "print(\"train_text_tokenized_stopwordspunctnum_removal\")\n",
    "logistic_singleword(train_text_tokenized_stopwordspunctnum_removal,test_text,train_labels,test_labels)\n",
    "print(\"train_text_lemmatized_stopwordspunctnum_removal\")\n",
    "logistic_singleword(train_text_lemmatized_stopwordspunctnum_removal,test_text,train_labels,test_labels)\n",
    "print(\"train_text_stemmed_stopwordspunctnum_removal\")\n",
    "logistic_singleword(train_text_stemmed_stopwordspunctnum_removal,test_text,train_labels,test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature_names = train_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_singleword_changing_max_features(train_data,test_data,train_labels,test_labels):\n",
    "    train_vectorizer = TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
    "                encoding='utf-8',input='content', lowercase=True, max_df=20000,\n",
    "                max_features=17001, min_df=1, ngram_range=(1,4), norm='l2',\n",
    "                preprocessor=None, smooth_idf=True, stop_words=None,\n",
    "                strip_accents=None, sublinear_tf=False,\n",
    "                token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True)\n",
    "    train_vecs = train_vectorizer.fit_transform(train_text)\n",
    "    test_vecs = TfidfVectorizer(vocabulary=train_vectorizer.vocabulary_).fit_transform(test_text)\n",
    "\n",
    "# train model\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    clf = LogisticRegression(C=10000.0, class_weight=None, dual=False, fit_intercept=True,\n",
    "                   intercept_scaling=1, l1_ratio=None, max_iter=10000,\n",
    "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
    "                   random_state=None, solver='saga', tol=0.0001, verbose=0,\n",
    "                   warm_start=False).fit(train_vecs, train_labels)\n",
    "\n",
    "# test model\n",
    "    test_pred = clf.predict(test_vecs)\n",
    "    from sklearn.metrics import precision_recall_fscore_support,accuracy_score\n",
    "    acc = accuracy_score(test_labels, test_pred)\n",
    "    pre, rec, f1, _ = precision_recall_fscore_support(test_labels, test_pred, average='macro')\n",
    "    # print(max_feature_num)\n",
    "    print('acc', acc)\n",
    "    print('precision', pre)\n",
    "    print('rec', rec)\n",
    "    print('f1', f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table of results \n",
    "print(\"train_text_tokenized\")\n",
    "logistic_singleword_changing_max_features(train_text_tokenized,test_text,train_labels,test_labels)\n",
    "print(\"train_text_lemmatized\")\n",
    "logistic_singleword_changing_max_features(train_text_lemmatized,test_text,train_labels,test_labels)\n",
    "print(\"train_text_stemmed\")\n",
    "logistic_singleword_changing_max_features(train_text_stemmed,test_text,train_labels,test_labels)\n",
    "print(\"train_text_tokenized_stopwordspunctnum_removal\")\n",
    "logistic_singleword_changing_max_features(train_text_tokenized_stopwordspunctnum_removal,test_text,train_labels,test_labels)\n",
    "print(\"train_text_lemmatized_stopwordspunctnum_removal\")\n",
    "logistic_singleword_changing_max_features(train_text_lemmatized_stopwordspunctnum_removal,test_text,train_labels,test_labels)\n",
    "print(\"train_text_stemmed_stopwordspunctnum_removal\")\n",
    "logistic_singleword_changing_max_features(train_text_stemmed_stopwordspunctnum_removal,test_text,train_labels,test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trying out with 2 tf-idf vectors one with single words and the other with ngrams for a homogenous dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "def feature_union(train_data,test_data,train_labels,test_labels):\n",
    "    \n",
    "    pipeline = Pipeline([\n",
    "    \n",
    "\n",
    "        # Use FeatureUnion to combine the features \n",
    "        ('union', FeatureUnion(\n",
    "            transformer_list=[\n",
    "\n",
    "                \n",
    "                ('tfidf1', Pipeline([\n",
    "                \n",
    "                    ('tfidf1', TfidfVectorizer(TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
    "                    encoding='utf-8',input='content', lowercase=True, max_df=20000,\n",
    "                    max_features=None, min_df=1, ngram_range=(1, 4), norm='l2',\n",
    "                    preprocessor=None, smooth_idf=True, stop_words=None,\n",
    "                    strip_accents=None, sublinear_tf=False,\n",
    "                    token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True))),\n",
    "                ])),\n",
    "\n",
    "                \n",
    "                ('tfidf2', Pipeline([\n",
    "                \n",
    "                    ('tfidf1', TfidfVectorizer(TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
    "                    encoding='utf-8',input='content', lowercase=True, max_df=20000,\n",
    "                    max_features=None, min_df=1, ngram_range=False, norm='l2',\n",
    "                    preprocessor=None, smooth_idf=True, stop_words= 'english',\n",
    "                    strip_accents=None, sublinear_tf=False,\n",
    "                    token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True))),\n",
    "                \n",
    "                ])),\n",
    "\n",
    "            \n",
    "\n",
    "            ],\n",
    "\n",
    "            # weight components in FeatureUnion\n",
    "            transformer_weights={\n",
    "                'tfidf1': 0.5,\n",
    "                'tfidf2': 0.5,\n",
    "            \n",
    "            },\n",
    "        )),\n",
    "\n",
    "        # Use a logistic classifier on the combined features\n",
    "        ('logistic', LogisticRegression(C=10000.0, class_weight=None, dual=False, fit_intercept=True,\n",
    "                       intercept_scaling=1, l1_ratio=None, max_iter=10000,\n",
    "                       multi_class='warn', n_jobs=None, penalty='l2',\n",
    "                       random_state=None, solver='saga', tol=0.0001, verbose=0,\n",
    "                       warm_start=False)),\n",
    "    ])\n",
    "    pipeline.fit(train_text, train_labels)\n",
    "    y = pipeline.predict(test_text)\n",
    "    print(classification_report(y, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"train_text_tokenized\")\n",
    "feature_union(train_text_tokenized,test_text,train_labels,test_labels)\n",
    "print(\"train_text_lemmatized\")\n",
    "feature_union(train_text_lemmatized,test_text,train_labels,test_labels)\n",
    "print(\"train_text_stemmed\")\n",
    "feature_union(train_text_stemmed,test_text,train_labels,test_labels)\n",
    "print(\"train_text_tokenized_stopwordspunctnum_removal\")\n",
    "feature_union(train_text_tokenized_stopwordspunctnum_removal,test_text,train_labels,test_labels)\n",
    "print(\"train_text_lemmatized_stopwordspunctnum_removal\")\n",
    "feature_union(train_text_lemmatized_stopwordspunctnum_removal,test_text,train_labels,test_labels)\n",
    "print(\"train_text_stemmed_stopwordspunctnum_removal\")\n",
    "feature_union(train_text_stemmed_stopwordspunctnum_removal,test_text,train_labels,test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "pipeline = Pipeline([\n",
    "    \n",
    "\n",
    "    # Use FeatureUnion to combine the features \n",
    "    ('union', FeatureUnion(\n",
    "        transformer_list=[\n",
    "\n",
    "            \n",
    "            ('tfidf1', Pipeline([\n",
    "                \n",
    "                ('tfidf1', TfidfVectorizer(TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
    "                encoding='utf-8',input='content', lowercase=True, max_df=20000,\n",
    "                max_features=None, min_df=1, ngram_range=(1, 2), norm='l2',\n",
    "                preprocessor=None, smooth_idf=True, stop_words=None,\n",
    "                strip_accents=None, sublinear_tf=False,\n",
    "                token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True))),\n",
    "            ])),\n",
    "\n",
    "            \n",
    "            ('tfidf2', Pipeline([\n",
    "                \n",
    "                ('tfidf2', TfidfVectorizer(TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
    "                encoding='utf-8',input='content', lowercase=True, max_df=20000,\n",
    "                max_features=None, min_df=1, ngram_range=False, norm='l2',\n",
    "                preprocessor=None, smooth_idf=True, stop_words= 'english',\n",
    "                strip_accents=None, sublinear_tf=False,\n",
    "                token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True))),\n",
    "                \n",
    "            ])),\n",
    "\n",
    "            \n",
    "\n",
    "        ],\n",
    "\n",
    "        # weight components in FeatureUnion\n",
    "        transformer_weights={\n",
    "            'tfidf1': 0.5,\n",
    "            'tfidf2': 0.5,\n",
    "            \n",
    "        },\n",
    "    )),\n",
    "\n",
    "    # Use a logistic classifier on the combined features\n",
    "    ('logistic', LogisticRegression(C=10000.0, class_weight=None, dual=False, fit_intercept=True,\n",
    "                   intercept_scaling=1, l1_ratio=None, max_iter=10000,\n",
    "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
    "                   random_state=None, solver='saga', tol=0.0001, verbose=0,\n",
    "                   warm_start=False)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('union',\n",
       "                 FeatureUnion(n_jobs=None,\n",
       "                              transformer_list=[('tfidf1',\n",
       "                                                 Pipeline(memory=None,\n",
       "                                                          steps=[('tfidf1',\n",
       "                                                                  TfidfVectorizer(analyzer='word',\n",
       "                                                                                  binary=False,\n",
       "                                                                                  decode_error='strict',\n",
       "                                                                                  dtype=<class 'numpy.float64'>,\n",
       "                                                                                  encoding='utf-8',\n",
       "                                                                                  input=TfidfVectorizer(analyzer='word',\n",
       "                                                                                                        binary=False,\n",
       "                                                                                                        decode_error='strict',\n",
       "                                                                                                        dtype=<class 'numpy.float64'>,\n",
       "                                                                                                        encodin...\n",
       "                                                          verbose=False))],\n",
       "                              transformer_weights={'tfidf1': 0.5,\n",
       "                                                   'tfidf2': 0.5},\n",
       "                              verbose=False)),\n",
       "                ('logistic',\n",
       "                 LogisticRegression(C=10000.0, class_weight=None, dual=False,\n",
       "                                    fit_intercept=True, intercept_scaling=1,\n",
       "                                    l1_ratio=None, max_iter=10000,\n",
       "                                    multi_class='warn', n_jobs=None,\n",
       "                                    penalty='l2', random_state=None,\n",
       "                                    solver='saga', tol=0.0001, verbose=0,\n",
       "                                    warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(train_text, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.89      0.89      0.89      2493\n",
      "         pos       0.89      0.89      0.89      2507\n",
      "\n",
      "    accuracy                           0.89      5000\n",
      "   macro avg       0.89      0.89      0.89      5000\n",
      "weighted avg       0.89      0.89      0.89      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "y = pipeline.predict(test_text)\n",
    "print(classification_report(y, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17001\n",
      "acc 0.893\n",
      "precision 0.8930564950946855\n",
      "rec 0.892976687627002\n",
      "f1 0.8929905446445249\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "#max_feature_num = 17001\n",
    "train_vectorizer = TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
    "                encoding='utf-8',input='content', lowercase=True, max_df=20000,\n",
    "                max_features=None, min_df=1, ngram_range=(1,2), norm='l2',\n",
    "                preprocessor=None, smooth_idf=True, stop_words=None,\n",
    "                strip_accents=None, sublinear_tf=False,\n",
    "                token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True)\n",
    "train_vecs = train_vectorizer.fit_transform(train_text_tokenized_stopwordspunctnum_removal)\n",
    "test_vecs = TfidfVectorizer(max_features=max_feature_num,vocabulary=train_vectorizer.vocabulary_).fit_transform(test_text)\n",
    "\n",
    "# train model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(C=10000.0, class_weight=None, dual=False, fit_intercept=True,\n",
    "                   intercept_scaling=1, l1_ratio=None, max_iter=10000,\n",
    "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
    "                   random_state=None, solver='saga', tol=0.0001, verbose=0,\n",
    "                   warm_start=False).fit(train_vecs, train_labels)\n",
    "\n",
    "# test model\n",
    "test_pred = clf.predict(test_vecs)\n",
    "from sklearn.metrics import precision_recall_fscore_support,accuracy_score\n",
    "acc = accuracy_score(test_labels, test_pred)\n",
    "pre, rec, f1, _ = precision_recall_fscore_support(test_labels, test_pred, average='macro')\n",
    "print(max_feature_num)\n",
    "print('acc', acc)\n",
    "print('precision', pre)\n",
    "print('rec', rec)\n",
    "print('f1', f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# save model and other necessary modules\n",
    "all_info_want_to_save = {\n",
    "    'model': clf,\n",
    "    'vectorizer':TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
    "                encoding='utf-8',input='content', lowercase=True, max_df=20000,\n",
    "                max_features=None, min_df=1, ngram_range=(1,2), norm='l2',\n",
    "                preprocessor=None, smooth_idf=True, stop_words=None,\n",
    "                strip_accents=None, sublinear_tf=False,\n",
    "                token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,vocabulary=train_vectorizer.vocabulary_) \n",
    "}\n",
    "save_path = open(\"sample_trained_model.pickle\",\"wb\")\n",
    "pickle.dump(all_info_want_to_save, save_path)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "o How you use the data to develop your model, e.g. how to split the data into\n",
    "  train/dev/test sets, how you clean/normalize the data and why. ?\n",
    " o Which features you have used in your model, and descriptions about why you\n",
    "  select these features. \n",
    "  \n",
    "o Which algorithms you have used and why you choose to use them.\n",
    "\n",
    "Summary :\n",
    "\n",
    "    Data was cleaned using :\n",
    "        Removal of punctuations\n",
    "        Removal of numbers \n",
    "        Removal of stop words\n",
    "    Data was transformed using :\n",
    "        Stemming \n",
    "        Lemmatization\n",
    "    \n",
    "    Ratio of train/dev/test :\n",
    "        Multiple ratios were used , Final ratio chosen [Train : 35000 , Dev : 5000 , Test : Hold -out Dataset ]This ratio           captured maximum information and produced the best model amongst others.\n",
    "\n",
    "\n",
    "\n",
    "#### 3) Data Modelling - TFIdf vectrorizer + Logistic regression in different conditions\n",
    "\n",
    "              i) logistic regression + tokenisation + stemming \n",
    "             ii) logistic regression + tokenisation + lemmatization\n",
    "            iii) logistic regression + tokenisation + data cleaning of specific types of features : stop words , numbers ,                  punctuation ,POS tags\n",
    "\n",
    "             iv) GridSearch with cross validation to find best parameters for logistic regression\n",
    "\n",
    "              v) Logistic regression with and without n-grams (combinations with different datasets)\n",
    "\n",
    "             vi) Joint TFID vectorizer \n",
    "             \n",
    "\n",
    "\n",
    "The intuition behind using tfidf is that if a word occurs multiple times in a document, we should boost its relevance as it should be more meaningful than other words that appear fewer times (TF). At the same time, if a word occurs many times in a document but also along many other documents, maybe it is because this word is just a frequent word; not because it was relevant or meaningful (IDF).\n",
    "\n",
    "i) After stemming was completed , it was noticed that many of the words did not match vocabulary words and this could be one of the major reason why the accuracy might not have been great. The test words would not have been matched the words in the tfidf vector. The influence of the possible reason stated above can be reduced by tweaking hyperparameters of logistic regression.\n",
    "\n",
    "ii)On that note lemmatization was expected to perform better compared to stemming since the words would be matched to dictionary words - it did marginally on occasion in different conditions. Lemmatization traces back all words to its root dictionary word and this could be the reason why it has not greatly outperformed stemming, it would have shortened many of the words by cutting of the suffix such as 'ing' ,'ed' ,etc.The influence of the possible reason stated above can be reduced by tweaking hyperparameters of logistic regression.\n",
    "\n",
    "iii) without stemming or lemmatization the model performed slightly better. Base words remained unchanged, punctuations were removed, numbers were removed. Could have performed much better with proper filtering of POS tags and as said earlier logistic regression hyperparameter tuning can improve this model much better. \n",
    "\n",
    "iv) There were a lot of grid searchs complete with cross validation , most of them took extremely long hours to process . I have attempted at identifying key parameters and its corresponding values post research on the scikitlearn website and previous labwork. The number of tuning parameters have been reduced due to computing and time restraints. The best gridsearchcv prediction accuracy crossed 90 % with dataset mention in item #3 . There are a lot more combinations that can be tried \n",
    "\n",
    "v) All of the examples provided above were of uni grams. Modelling bi-grams and higher with the  datasets mentioned above was also attempted. An interesting observation is that bigrams worked much better with stop words involved which proved a logical deduction.Excluding stop words did not help the model.\n",
    "\n",
    "vi)Having used uni grams,Bi-grams , I have also tried merging two tfidf vectors. The first tfidf vector represent features with unigrams and the second tfidf vector represents bigram features. I have to experiment a bit more with the feature union.Combining features of multiple tfidf vectors results in a broad feature vector that could possibly capture a lot more than a single tfidf vector. \n",
    "example image : https://michelleful.github.io/code-blog/assets/images/201506/more_complex_pipeline.png"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
